{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replicating CPS imputation via logistic regression of:\n",
    "# 1.whether pay is received on an hourly basis; \n",
    "# 2. employer size; \n",
    "# 3. number of employers that the person worked for in the last 12 months; \n",
    "# 4. weekly pay (derived from weeks worked, separate regression not needed)\n",
    "# 5. weeks worked \n",
    "\n",
    "# Housekeeping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "import mord as m\n",
    "\n",
    "def load_cps(data):\n",
    "    global df\n",
    "    df = pd.read_csv(data)\n",
    "        \n",
    "def clean_cps(df):\n",
    "    # data cleaning/var generation\n",
    "    # strip out NIU/missing values (coded as '999'...)\n",
    "\n",
    "    # Making zero/negative earnings into NaN so we can take natural log\n",
    "    df['lnearn']=df['pearnval'].mask(df['pearnval'] <= 0, np.nan)\n",
    "    df['lnearn']=np.log(df['lnearn'])\n",
    "    # Making other values 0 per ACM code\n",
    "    df.loc[(df['pearnval']<=0),'lnearn']=0\n",
    "\n",
    "\n",
    "    #Create dummies for logit regressions\n",
    "    df['female']=0\n",
    "    df.loc[(df['a_sex']==2),'female']=1\n",
    "\n",
    "    # Education dummies\n",
    "    df['lths']=0\n",
    "    df['somecol']=0\n",
    "    df['ba']=0\n",
    "    df['maplus']=0\n",
    "    df.loc[(df['a_hga']<=38),'lths']=1\n",
    "    df.loc[(df['a_hga']>=40) & (df['a_hga']<=42 ),'somecol']=1\n",
    "    df.loc[(df['a_hga']==43),'ba']=1\n",
    "    df.loc[(df['a_hga']>=44),'maplus']=1\n",
    "\n",
    "    # Race/ethnicity dummies\n",
    "    df['black']=0\n",
    "    df['hispanic']=0\n",
    "    df['asian']=0\n",
    "    df['other']=0\n",
    "    df.loc[(df['prdtrace']==2)&(df['pehspnon']==2),'black']=1\n",
    "    df.loc[(df['prdtrace']==4)&(df['pehspnon']==2),'asian']=1\n",
    "    df.loc[((df['prdtrace']==3)|((df['prdtrace']>=5)&(df['prdtrace']<=26)))&(df['pehspnon']==2),'other']=1\n",
    "    df.loc[(df['pehspnon']==1),'hispanic']=1\n",
    "\n",
    "    #age squared var\n",
    "    df['agesq']=df['a_age']*df['a_age']\n",
    "\n",
    "    #occupation and industry categories\n",
    "    # hmm some missing are coded in with stata regressions\n",
    "    df['occ_1']=0\n",
    "    df['occ_2']=0\n",
    "    df['occ_3']=0\n",
    "    df['occ_4']=0\n",
    "    df['occ_5']=0\n",
    "    df['occ_6']=0\n",
    "    df['occ_7']=0\n",
    "    df['occ_8']=0\n",
    "    df['occ_9']=0\n",
    "    df['occ_10']=0\n",
    "    df['maj_occ']=0\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_1']=np.nan\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_2']=np.nan\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_3']=np.nan\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_4']=np.nan\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_5']=np.nan\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_6']=np.nan\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_7']=np.nan\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_8']=np.nan\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_9']=np.nan\n",
    "    df.loc[(df['a_mjocc']==0)|(df['a_mjocc']==11),'occ_10']=np.nan\n",
    "    df.loc[(df['a_mjocc']==1), 'occ_1'] =1\n",
    "    df.loc[(df['a_mjocc']==2), 'occ_2'] =1\n",
    "    df.loc[(df['a_mjocc']==3), 'occ_3'] =1\n",
    "    df.loc[(df['a_mjocc']==4), 'occ_4'] =1\n",
    "    df.loc[(df['a_mjocc']==5), 'occ_5'] =1\n",
    "    df.loc[(df['a_mjocc']==6), 'occ_6'] =1\n",
    "    df.loc[(df['a_mjocc']==7), 'occ_7'] =1\n",
    "    df.loc[(df['a_mjocc']==8), 'occ_8'] =1\n",
    "    df.loc[(df['a_mjocc']==9), 'occ_9'] =1\n",
    "    df.loc[(df['a_mjocc']==10), 'occ_10'] =1\n",
    "    df['vmaj_occ']=0\n",
    "    df.loc[df['maj_occ']>0,'vmaj_occ']=1\n",
    "\n",
    "    df['ind_1']=0\n",
    "    df['ind_2']=0\n",
    "    df['ind_3']=0\n",
    "    df['ind_4']=0\n",
    "    df['ind_5']=0\n",
    "    df['ind_6']=0\n",
    "    df['ind_7']=0\n",
    "    df['ind_8']=0\n",
    "    df['ind_9']=0\n",
    "    df['ind_10']=0\n",
    "    df['ind_11']=0\n",
    "    df['ind_12']=0\n",
    "    df['ind_13']=0\n",
    "    df['maj_ind']=0\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_1']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_2']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_3']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_4']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_5']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_6']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_7']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_8']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_9']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_10']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_11']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_12']=np.nan\n",
    "    df.loc[(df['a_mjind']==0)|(df['a_mjind']==14),'ind_13']=np.nan\n",
    "    \n",
    "    df.loc[(df['a_mjind']==1), 'ind_1'] =1\n",
    "    df.loc[(df['a_mjind']==2), 'ind_2'] =1\n",
    "    df.loc[(df['a_mjind']==3), 'ind_3'] =1\n",
    "    df.loc[(df['a_mjind']==4), 'ind_4'] =1\n",
    "    df.loc[(df['a_mjind']==5), 'ind_5'] =1\n",
    "    df.loc[(df['a_mjind']==6), 'ind_6'] =1\n",
    "    df.loc[(df['a_mjind']==7), 'ind_7'] =1\n",
    "    df.loc[(df['a_mjind']==8), 'ind_8'] =1\n",
    "    df.loc[(df['a_mjind']==9), 'ind_9'] =1\n",
    "    df.loc[(df['a_mjind']==10), 'ind_10'] =1\n",
    "    df.loc[(df['a_mjind']==11), 'ind_11'] =1\n",
    "    df.loc[(df['a_mjind']==12), 'ind_12'] =1\n",
    "    df.loc[(df['a_mjind']==13), 'ind_13'] =1\n",
    "\n",
    "    df['vmaj_ind']=0\n",
    "    df.loc[df['maj_ind']>0,'vmaj_ind']=1\n",
    "\n",
    "    df['paid_hrly']=np.nan\n",
    "    df.loc[(df['prerelg']==1),'paid_hrly']=0\n",
    "    df.loc[(df['prerelg']==1)&df['a_hrlywk']==1,'paid_hrly']=1\n",
    "    \n",
    "    df.loc[df['hiemp']==0,'hiemp']=np.nan\n",
    "    df.loc[df['hiemp']==2,'hiemp']=0\n",
    "    \n",
    "def cps_logit_fit(dic,conditional, data):\n",
    "    \"\"\"\n",
    "    This estimates logit regression coefficients from CPS\n",
    "    dic:  dictionary of specifications\n",
    "    d:    CPS dataset\n",
    "    \"\"\"\n",
    "    for impute in dic:\n",
    "        # Subset Data\n",
    "        if conditional[impute]==\"\":\n",
    "            d = data[:]\n",
    "        else:    \n",
    "            d = data[eval(conditional[impute])]\n",
    "        y, X = patsy.dmatrices(dic[impute], d, return_type = 'dataframe')    \n",
    "        \n",
    "        # strip out intercept column\n",
    "        X=X.iloc[:,1:]\n",
    "        # Get Weights          \n",
    "        w = d['marsupwt'][X.index]\n",
    "        \n",
    "        # Run model\n",
    "        clf = linear_model.LogisticRegression(solver='newton-cg', C=99999999)\n",
    "            # suppressing warnings generated from this, not concerning when we are just \n",
    "            # looking for absolute replication of ACM at this point\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        clf.fit(X, y.values.ravel(), sample_weight = w)\n",
    "        warnings.filterwarnings(\"default\")\n",
    "        \n",
    "         # Save estimates to file\n",
    "        co_names = [x.split(\")\")[0] for x in list(X)]\n",
    "        co_names = [x.replace(\"C(\",\"\") for x in co_names]\n",
    "        raw_data = {'var': co_names, 'est': clf.coef_[0]}\n",
    "        out_df = pd.DataFrame(raw_data, columns=['var', 'est'])\n",
    "        out_df = out_df.append(pd.DataFrame(['Intercept'],columns=['var']), ignore_index=True)\n",
    "        out_df.iloc[17,0]=clf.intercept_\n",
    "        out_df.to_csv(\"./estimates/\"+\"CPS\"+ \"_\" +impute + '.csv',index=False,header=True)\n",
    "\n",
    "def cps_ordered_logit_fit(dic,conditional, data):\n",
    "    \"\"\"\n",
    "    This estimates ordered logit regression coefficients from CPS\n",
    "    dic:  dictionary of specifications\n",
    "    d:    CPS dataset\n",
    "    \"\"\"\n",
    "    for impute in dic:\n",
    "        # Subset Data\n",
    "        if conditional[impute]==\"\":\n",
    "            d = data[:]\n",
    "        else:    \n",
    "            d = data[eval(conditional[impute])]\n",
    "        y, X = patsy.dmatrices(dic[impute], d, return_type = 'dataframe')    \n",
    "        \n",
    "        # strip out intercept column\n",
    "        X=X.iloc[:,1:]\n",
    "        # Get Weights          \n",
    "        w = d['marsupwt'][X.index]\n",
    "        \n",
    "        # Run model\n",
    "        clf = linear_model.LogisticRegression(solver='newton-cg', C=99999999)\n",
    "            # suppressing warnings generated from this, not concerning when we are just \n",
    "            # looking for absolute replication of ACM at this point\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        clf.fit(X, y.values.ravel(), sample_weight = w)\n",
    "        warnings.filterwarnings(\"default\")\n",
    "        \n",
    "         # Save estimates to file\n",
    "        co_names = [x.split(\")\")[0] for x in list(X)]\n",
    "        co_names = [x.replace(\"C(\",\"\") for x in co_names]\n",
    "        raw_data = {'var': co_names, 'est': clf.coef_[0]}\n",
    "        out_df = pd.DataFrame(raw_data, columns=['var', 'est'])\n",
    "        out_df = out_df.append(pd.DataFrame(['Intercept'],columns=['var']), ignore_index=True)\n",
    "        out_df.iloc[17,0]=clf.intercept_\n",
    "        out_df.to_csv(\"./estimates/\"+\"CPS\"+ \"_\" +impute + '.csv',index=False,header=True)\n",
    "\n",
    "        \n",
    "        \n",
    "load_cps('data/CPS2014extract.csv')\n",
    "clean_cps(df)\n",
    "\n",
    "# # logit for hourly paid regression\n",
    "# specif = {\"paid_hrly\":  \"paid_hrly ~ C(female) + C(black) + a_age + agesq + C(ba)\"\n",
    "#           + \"+ C(maplus) + C(occ_1) + C(occ_3) + C(occ_5) + C(occ_7) + C(occ_8)\"\n",
    "#           + \"+ C(occ_9) + C(occ_10) + C(ind_5) + C(ind_8) + C(ind_11) + C(ind_12)\"}  \n",
    "# cond = {\"paid_hrly\": \"\"}\n",
    "# cps_logit_fit(specif,cond,df)\n",
    "\n",
    "\n",
    "#ordered logit for number of employers and weeks worked\n",
    "specif = {\"num_employers\":  \"phmemprs ~ a_age + agesq + C(asian) + C(hispanic)\"+\n",
    "          \"+ C(lths) + C(somecol) + C(ba) + C(maplus) + C(lnearn)\"+\n",
    "          \"+ C(hiemp) + C(ind_4) + C(ind_5) + C(ind_6) + C(ind_8)\"+\n",
    "          \"+ C(ind_13) + C(occ_1) + C(occ_6) + C(occ_7) + C(occ_9)+ C(occ_10)\"}\n",
    "cond = {\"num_employers\": \"\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.864411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.143497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lths</td>\n",
       "      <td>-0.250157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>somecol</td>\n",
       "      <td>0.680293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ba</td>\n",
       "      <td>0.069219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>maplus</td>\n",
       "      <td>-0.553352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hiemp</td>\n",
       "      <td>0.315715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ind_4</td>\n",
       "      <td>-0.603732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ind_5</td>\n",
       "      <td>-0.246710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ind_6</td>\n",
       "      <td>-0.210841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ind_8</td>\n",
       "      <td>0.297142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ind_13</td>\n",
       "      <td>-0.332350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>occ_1</td>\n",
       "      <td>0.279615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>occ_6</td>\n",
       "      <td>-0.009268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>occ_7</td>\n",
       "      <td>-0.115143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>occ_9</td>\n",
       "      <td>-0.561325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>occ_10</td>\n",
       "      <td>-0.075844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a_age</td>\n",
       "      <td>-0.521922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>agesq</td>\n",
       "      <td>0.005481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lnearn</td>\n",
       "      <td>0.433109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         var       est\n",
       "0      asian  0.864411\n",
       "1   hispanic  0.143497\n",
       "2       lths -0.250157\n",
       "3    somecol  0.680293\n",
       "4         ba  0.069219\n",
       "5     maplus -0.553352\n",
       "6      hiemp  0.315715\n",
       "7      ind_4 -0.603732\n",
       "8      ind_5 -0.246710\n",
       "9      ind_6 -0.210841\n",
       "10     ind_8  0.297142\n",
       "11    ind_13 -0.332350\n",
       "12     occ_1  0.279615\n",
       "13     occ_6 -0.009268\n",
       "14     occ_7 -0.115143\n",
       "15     occ_9 -0.561325\n",
       "16    occ_10 -0.075844\n",
       "17     a_age -0.521922\n",
       "18     agesq  0.005481\n",
       "19    lnearn  0.433109"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "d = df[df[\"prerelg\"]==1].dropna().sample(n=100)\n",
    "\n",
    "y, X = patsy.dmatrices( \"phmemprs ~ a_age + agesq + C(asian) + C(hispanic)\"+\n",
    "          \"+ C(lths) + C(somecol) + C(ba) + C(maplus) + lnearn\"+\n",
    "          \"+ C(hiemp) + C(ind_4) + C(ind_5) + C(ind_6) + C(ind_8)\"+\n",
    "          \"+ C(ind_13) + C(occ_1) + C(occ_6) + C(occ_7) + C(occ_9)+ C(occ_10)\", d, return_type = 'dataframe') \n",
    "X=X.iloc[:,1:]\n",
    "c= m.LogisticAT()\n",
    "c.fit(X, y.values.ravel().astype('int')) \n",
    "#, sample_weight = d['marsupwt'][X.index].astype('int')\n",
    "co_names = [x.split(\")\")[0] for x in list(X)]\n",
    "co_names = [x.replace(\"C(\",\"\") for x in co_names]\n",
    "raw_data = {'var': co_names, 'est': c.coef_}\n",
    "out_df = pd.DataFrame(raw_data, columns=['var', 'est'])\n",
    "#out_df = out_df.append(pd.DataFrame(['Intercept'],columns=['var']), ignore_index=True)\n",
    "#out_df.iloc[len(co_names),0]=c.intercept_\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(co_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0     count\n",
      "phmemprs       \n",
      "1         61042\n",
      "2          5662\n",
      "3          1350\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(index=df['phmemprs'], columns='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
